{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":63741,"databundleVersionId":6966274,"sourceType":"competition"}],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-14T10:45:11.257777Z","iopub.execute_input":"2023-12-14T10:45:11.258048Z","iopub.status.idle":"2023-12-14T10:45:11.599714Z","shell.execute_reply.started":"2023-12-14T10:45:11.258016Z","shell.execute_reply":"2023-12-14T10:45:11.598813Z"},"trusted":true},"outputs":[{"name":"stdout","text":"/kaggle/input/book-rating-prediction01/sample_submission.csv\n/kaggle/input/book-rating-prediction01/Train.csv\n/kaggle/input/book-rating-prediction01/Test.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2023-12-14T10:47:05.151815Z","iopub.execute_input":"2023-12-14T10:47:05.152572Z","iopub.status.idle":"2023-12-14T10:47:05.156721Z","shell.execute_reply.started":"2023-12-14T10:47:05.152536Z","shell.execute_reply":"2023-12-14T10:47:05.155811Z"},"trusted":true},"outputs":[],"execution_count":2},{"cell_type":"code","source":"dataset = pd.read_csv(\"/kaggle/input/book-rating-prediction01/Train.csv\",encoding=\"latin\")\ndf = pd.DataFrame(dataset)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-14T10:47:06.328395Z","iopub.execute_input":"2023-12-14T10:47:06.329229Z","iopub.status.idle":"2023-12-14T10:47:27.074790Z","shell.execute_reply.started":"2023-12-14T10:47:06.329195Z","shell.execute_reply":"2023-12-14T10:47:27.073837Z"},"trusted":true},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                            user_id   book_id  \\\n0  e8730ce3ed5e9762038d160e23d47d79      2187   \n1  26317e667d9141ad245dd2c18be52d77     47212   \n2  bf9640b81a047ee70b4f918082492f1d     40483   \n3  34aa99d428ad98679c3e45d117243f55  19095025   \n4  6b3f929609c9d97628807d13b59b0b22   9464746   \n\n                          review_id  \\\n0  1c6af3913167e3d9d26be5a29d8df1aa   \n1  fa1f648451baf909683ea40bda3a06fe   \n2  ae2c43f1062ab1dae0ad51f5ea3c7c56   \n3  3eb21a560e2afb02ace9e44d6fe76c8b   \n4  6caffed66bddb57550e777f04823fdd6   \n\n                                         review_text  \\\n0  4.5 stars \\n I loved this book! It was incredi...   \n1  I've had my dad and friend after me to read th...   \n2  Anyone desiring to start an exploration of S&M...   \n3  3.75 stars \\n Mal is the best. He's crazy fun ...   \n4  I would like to begin by saying how much I app...   \n\n                       date_added                    date_updated  \\\n0  Fri May 23 13:53:31 -0700 2014  Sun Apr 03 03:56:27 -0700 2016   \n1  Thu Jan 05 21:23:23 -0800 2017  Sun Jan 08 21:09:19 -0800 2017   \n2  Tue Feb 18 03:29:28 -0800 2014  Fri Feb 28 01:24:54 -0800 2014   \n3  Fri May 08 17:06:08 -0700 2015  Sun May 21 17:12:59 -0700 2017   \n4  Tue Feb 08 15:47:53 -0800 2011  Sat Nov 05 21:12:58 -0700 2011   \n\n                          read_at                      started_at  n_votes  \\\n0  Sun Mar 29 00:00:00 -0700 2015  Mon Aug 25 00:00:00 -0700 2014        0   \n1  Sun Jan 08 00:00:00 -0800 2017  Thu Jan 05 00:00:00 -0800 2017        1   \n2  Fri Feb 28 01:54:07 -0800 2014  Tue Feb 18 00:00:00 -0800 2014        1   \n3  Mon Sep 07 00:00:00 -0700 2015  Sun Sep 06 00:00:00 -0700 2015        1   \n4  Sat Nov 05 00:00:00 -0700 2011  Sun Oct 30 00:00:00 -0700 2011        0   \n\n   n_comments  rating  \n0           0       4  \n1           0       4  \n2           1       3  \n3           0       4  \n4           0       5  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>book_id</th>\n      <th>review_id</th>\n      <th>review_text</th>\n      <th>date_added</th>\n      <th>date_updated</th>\n      <th>read_at</th>\n      <th>started_at</th>\n      <th>n_votes</th>\n      <th>n_comments</th>\n      <th>rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>e8730ce3ed5e9762038d160e23d47d79</td>\n      <td>2187</td>\n      <td>1c6af3913167e3d9d26be5a29d8df1aa</td>\n      <td>4.5 stars \\n I loved this book! It was incredi...</td>\n      <td>Fri May 23 13:53:31 -0700 2014</td>\n      <td>Sun Apr 03 03:56:27 -0700 2016</td>\n      <td>Sun Mar 29 00:00:00 -0700 2015</td>\n      <td>Mon Aug 25 00:00:00 -0700 2014</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>26317e667d9141ad245dd2c18be52d77</td>\n      <td>47212</td>\n      <td>fa1f648451baf909683ea40bda3a06fe</td>\n      <td>I've had my dad and friend after me to read th...</td>\n      <td>Thu Jan 05 21:23:23 -0800 2017</td>\n      <td>Sun Jan 08 21:09:19 -0800 2017</td>\n      <td>Sun Jan 08 00:00:00 -0800 2017</td>\n      <td>Thu Jan 05 00:00:00 -0800 2017</td>\n      <td>1</td>\n      <td>0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>bf9640b81a047ee70b4f918082492f1d</td>\n      <td>40483</td>\n      <td>ae2c43f1062ab1dae0ad51f5ea3c7c56</td>\n      <td>Anyone desiring to start an exploration of S&amp;M...</td>\n      <td>Tue Feb 18 03:29:28 -0800 2014</td>\n      <td>Fri Feb 28 01:24:54 -0800 2014</td>\n      <td>Fri Feb 28 01:54:07 -0800 2014</td>\n      <td>Tue Feb 18 00:00:00 -0800 2014</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>34aa99d428ad98679c3e45d117243f55</td>\n      <td>19095025</td>\n      <td>3eb21a560e2afb02ace9e44d6fe76c8b</td>\n      <td>3.75 stars \\n Mal is the best. He's crazy fun ...</td>\n      <td>Fri May 08 17:06:08 -0700 2015</td>\n      <td>Sun May 21 17:12:59 -0700 2017</td>\n      <td>Mon Sep 07 00:00:00 -0700 2015</td>\n      <td>Sun Sep 06 00:00:00 -0700 2015</td>\n      <td>1</td>\n      <td>0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6b3f929609c9d97628807d13b59b0b22</td>\n      <td>9464746</td>\n      <td>6caffed66bddb57550e777f04823fdd6</td>\n      <td>I would like to begin by saying how much I app...</td>\n      <td>Tue Feb 08 15:47:53 -0800 2011</td>\n      <td>Sat Nov 05 21:12:58 -0700 2011</td>\n      <td>Sat Nov 05 00:00:00 -0700 2011</td>\n      <td>Sun Oct 30 00:00:00 -0700 2011</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"new_df = df\nnew_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-14T10:47:27.076337Z","iopub.execute_input":"2023-12-14T10:47:27.076631Z","iopub.status.idle":"2023-12-14T10:47:27.089627Z","shell.execute_reply.started":"2023-12-14T10:47:27.076605Z","shell.execute_reply":"2023-12-14T10:47:27.088672Z"},"trusted":true},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                            user_id   book_id  \\\n0  e8730ce3ed5e9762038d160e23d47d79      2187   \n1  26317e667d9141ad245dd2c18be52d77     47212   \n2  bf9640b81a047ee70b4f918082492f1d     40483   \n3  34aa99d428ad98679c3e45d117243f55  19095025   \n4  6b3f929609c9d97628807d13b59b0b22   9464746   \n\n                          review_id  \\\n0  1c6af3913167e3d9d26be5a29d8df1aa   \n1  fa1f648451baf909683ea40bda3a06fe   \n2  ae2c43f1062ab1dae0ad51f5ea3c7c56   \n3  3eb21a560e2afb02ace9e44d6fe76c8b   \n4  6caffed66bddb57550e777f04823fdd6   \n\n                                         review_text  \\\n0  4.5 stars \\n I loved this book! It was incredi...   \n1  I've had my dad and friend after me to read th...   \n2  Anyone desiring to start an exploration of S&M...   \n3  3.75 stars \\n Mal is the best. He's crazy fun ...   \n4  I would like to begin by saying how much I app...   \n\n                       date_added                    date_updated  \\\n0  Fri May 23 13:53:31 -0700 2014  Sun Apr 03 03:56:27 -0700 2016   \n1  Thu Jan 05 21:23:23 -0800 2017  Sun Jan 08 21:09:19 -0800 2017   \n2  Tue Feb 18 03:29:28 -0800 2014  Fri Feb 28 01:24:54 -0800 2014   \n3  Fri May 08 17:06:08 -0700 2015  Sun May 21 17:12:59 -0700 2017   \n4  Tue Feb 08 15:47:53 -0800 2011  Sat Nov 05 21:12:58 -0700 2011   \n\n                          read_at                      started_at  n_votes  \\\n0  Sun Mar 29 00:00:00 -0700 2015  Mon Aug 25 00:00:00 -0700 2014        0   \n1  Sun Jan 08 00:00:00 -0800 2017  Thu Jan 05 00:00:00 -0800 2017        1   \n2  Fri Feb 28 01:54:07 -0800 2014  Tue Feb 18 00:00:00 -0800 2014        1   \n3  Mon Sep 07 00:00:00 -0700 2015  Sun Sep 06 00:00:00 -0700 2015        1   \n4  Sat Nov 05 00:00:00 -0700 2011  Sun Oct 30 00:00:00 -0700 2011        0   \n\n   n_comments  rating  \n0           0       4  \n1           0       4  \n2           1       3  \n3           0       4  \n4           0       5  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>book_id</th>\n      <th>review_id</th>\n      <th>review_text</th>\n      <th>date_added</th>\n      <th>date_updated</th>\n      <th>read_at</th>\n      <th>started_at</th>\n      <th>n_votes</th>\n      <th>n_comments</th>\n      <th>rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>e8730ce3ed5e9762038d160e23d47d79</td>\n      <td>2187</td>\n      <td>1c6af3913167e3d9d26be5a29d8df1aa</td>\n      <td>4.5 stars \\n I loved this book! It was incredi...</td>\n      <td>Fri May 23 13:53:31 -0700 2014</td>\n      <td>Sun Apr 03 03:56:27 -0700 2016</td>\n      <td>Sun Mar 29 00:00:00 -0700 2015</td>\n      <td>Mon Aug 25 00:00:00 -0700 2014</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>26317e667d9141ad245dd2c18be52d77</td>\n      <td>47212</td>\n      <td>fa1f648451baf909683ea40bda3a06fe</td>\n      <td>I've had my dad and friend after me to read th...</td>\n      <td>Thu Jan 05 21:23:23 -0800 2017</td>\n      <td>Sun Jan 08 21:09:19 -0800 2017</td>\n      <td>Sun Jan 08 00:00:00 -0800 2017</td>\n      <td>Thu Jan 05 00:00:00 -0800 2017</td>\n      <td>1</td>\n      <td>0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>bf9640b81a047ee70b4f918082492f1d</td>\n      <td>40483</td>\n      <td>ae2c43f1062ab1dae0ad51f5ea3c7c56</td>\n      <td>Anyone desiring to start an exploration of S&amp;M...</td>\n      <td>Tue Feb 18 03:29:28 -0800 2014</td>\n      <td>Fri Feb 28 01:24:54 -0800 2014</td>\n      <td>Fri Feb 28 01:54:07 -0800 2014</td>\n      <td>Tue Feb 18 00:00:00 -0800 2014</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>34aa99d428ad98679c3e45d117243f55</td>\n      <td>19095025</td>\n      <td>3eb21a560e2afb02ace9e44d6fe76c8b</td>\n      <td>3.75 stars \\n Mal is the best. He's crazy fun ...</td>\n      <td>Fri May 08 17:06:08 -0700 2015</td>\n      <td>Sun May 21 17:12:59 -0700 2017</td>\n      <td>Mon Sep 07 00:00:00 -0700 2015</td>\n      <td>Sun Sep 06 00:00:00 -0700 2015</td>\n      <td>1</td>\n      <td>0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6b3f929609c9d97628807d13b59b0b22</td>\n      <td>9464746</td>\n      <td>6caffed66bddb57550e777f04823fdd6</td>\n      <td>I would like to begin by saying how much I app...</td>\n      <td>Tue Feb 08 15:47:53 -0800 2011</td>\n      <td>Sat Nov 05 21:12:58 -0700 2011</td>\n      <td>Sat Nov 05 00:00:00 -0700 2011</td>\n      <td>Sun Oct 30 00:00:00 -0700 2011</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"df.dtypes","metadata":{"execution":{"iopub.status.busy":"2023-12-14T11:06:08.428887Z","iopub.execute_input":"2023-12-14T11:06:08.429318Z","iopub.status.idle":"2023-12-14T11:06:08.437035Z","shell.execute_reply.started":"2023-12-14T11:06:08.429283Z","shell.execute_reply":"2023-12-14T11:06:08.436162Z"},"trusted":true},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"user_id         object\nbook_id          int64\nreview_id       object\nreview_text     object\ndate_added      object\ndate_updated    object\nread_at         object\nstarted_at      object\nn_votes          int64\nn_comments       int64\nrating           int64\ndtype: object"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"df['rating'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-12-14T11:23:18.487856Z","iopub.execute_input":"2023-12-14T11:23:18.488685Z","iopub.status.idle":"2023-12-14T11:23:18.522217Z","shell.execute_reply.started":"2023-12-14T11:23:18.488650Z","shell.execute_reply":"2023-12-14T11:23:18.521290Z"},"trusted":true},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"rating\n4    219581\n5    185505\n3    132280\n2     50839\n0     21692\n1     20103\nName: count, dtype: int64"},"metadata":{}}],"execution_count":7},{"cell_type":"markdown","source":"### HTML Tag and urls removal","metadata":{}},{"cell_type":"code","source":"import re\n\ndef remove_html_tags_and_urls(text):\n    clean = re.sub(r'[\\t\\n]', '', text)\n    clean = re.sub(r'<.*?>', '', clean)\n    clean = re.sub(r'https?://\\S+|www\\.\\S+', '', clean)\n    return clean","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Remove Punctuation","metadata":{}},{"cell_type":"code","source":"import string\ndef remove_punc(text):\n    return text.translate(str.maketrans('','', string.punctuation))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Stopwords Removal","metadata":{}},{"cell_type":"code","source":"from nltk.corpus import stopwords\n\nstop_words = set(stopwords.words('english'))\n\ndef remove_stopword(text):\n    words = text.split()\n    filtered_words = [word for word in words if word not in stop_words]\n    return ' '.join(filtered_words)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Tokenization and Stemming","metadata":{}},{"cell_type":"code","source":"from nltk.stem import PorterStemmer\nclass TwoWayStemmer:\n    def __init__(self):\n        self.stemmer = PorterStemmer()\n        self.stem_dict = {}\n\n    def stem_text(self, text):\n        stemmed_text = []\n        for word in text.split():\n            stemmed_word = self.stemmer.stem(word)\n            if stemmed_word not in self.stem_dict:\n                self.stem_dict[stemmed_word] = [word]\n            else:\n                if word not in self.stem_dict[stemmed_word]:\n                    self.stem_dict[stemmed_word].append(word)\n            stemmed_text.append(stemmed_word)\n        return ' '.join(stemmed_text)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Applying functions\nnew_df['review_text'] = new_df['review_text'].str.lower()\nnew_df['review_text'] = new_df['review_text'].apply(remove_html_tags_and_urls)\nnew_df['review_text'] = new_df['review_text'].apply(lambda x: ' '.join([word for word in str(x).split() if not word.isdigit()]))\nnew_df['review_text'] = new_df['review_text'].apply(remove_stopword)\nnew_df['review_text'] = new_df['review_text'].apply(remove_punc)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"two_way_stemmer = TwoWayStemmer()\n\n# Assuming 'train_df' is your training dataframe with 'review_text' column\nnew_df['review_text'] = new_df['review_text'].apply(lambda x: two_way_stemmer.stem_text(x))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### PreProcessing","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\nimport scipy.sparse as sp\n\nX = new_df['review_text']\ny = new_df['rating']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n\n# TF-IDF vectorization for text data\nvectorizer = TfidfVectorizer()\nX_train_tfidf = vectorizer.fit_transform(X_train)\nX_test_tfidf = vectorizer.transform(X_test)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Input, Dense, Dropout, Activation, BatchNormalization\nfrom keras.models import Model\nfrom keras.layers import Dense, Dropout\nfrom keras.utils import to_categorical\nfrom keras.layers import LeakyReLU\nfrom keras.regularizers import l2\nimport tensorflow as tf\nimport numpy as np\nimport keras.backend as K\n\n# Define ELU activation function\ndef elu_activation(x):\n    return K.elu(x, alpha=0.1)\n\n# Convert y_train to categorical labels\ny_train_categorical = to_categorical(y_train, num_classes=6)\n\n# Input layer\nmodel = Sequential()\nmodel.add(Dense(128, input_shape=(X_train_tfidf.shape[1],), kernel_regularizer=l2(0.001)))\nmodel.add(LeakyReLU(alpha=0.1))\nmodel.add(Dropout(0.5))\nmodel.add(BatchNormalization())\nmodel.add(Dense(64, kernel_regularizer=l2(0.001)))\nmodel.add(LeakyReLU(alpha=0.1))\nmodel.add(Dropout(0.3))\nmodel.add(BatchNormalization())\nmodel.add(Dense(6, activation='softmax'))  # Output layer with softmax for classification\n\n# Compile the model\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\n\n# Convert Scipy sparse matrices to TensorFlow's SparseTensor\ndef convert_to_sparse_tensor(sparse_matrix):\n    coo = sparse_matrix.tocoo()\n    indices = np.mat([coo.row, coo.col]).transpose()\n    return tf.sparse.SparseTensor(indices, coo.data, coo.shape)\n\n# Train-test split for validation\nX_train_split, X_val, y_train_split, y_val = train_test_split(\n    X_train_tfidf, y_train_categorical, test_size=0.1, random_state=42)\n\n# Convert X_train_split and X_val to SparseTensor\nX_train_split_sparse = convert_to_sparse_tensor(X_train_split)\nX_val_sparse = convert_to_sparse_tensor(X_val)\n\n# Reorder the SparseTensor\nX_train_split_reordered = tf.sparse.reorder(X_train_split_sparse)\nX_val_reordered = tf.sparse.reorder(X_val_sparse)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Train the model with the reordered sparse matrices for validation data\nhistory = model.fit(\n    X_train_split_reordered, y_train_split,\n    epochs=50,\n    batch_size=32,\n    validation_data=(X_val_reordered, y_val)\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Convert X_test_tfidf to TensorFlow's SparseTensor format\nX_test_sparse = convert_to_sparse_tensor(X_test_tfidf)\n\n# Reorder the SparseTensor\nX_test_reordered = tf.sparse.reorder(X_test_sparse)\n\n# Convert y_test to categorical labels\ny_test_categorical = to_categorical(y_test, num_classes=6)\n\n# Evaluate the model on the reordered test data\ntest_loss, test_accuracy = model.evaluate(X_test_reordered, y_test_categorical)\n\nprint(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\nprint(f\"Test Loss: {test_loss}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_df = pd.read_csv(\"/kaggle/input/book-rating-prediction01/Test.csv\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Applying functions\ntest_df['review_text'] = test_df['review_text'].str.lower()\ntest_df['review_text'] = test_df['review_text'].apply(remove_html_tags_and_urls)\ntest_df['review_text'] = test_df['review_text'].apply(lambda x: ' '.join([word for word in str(x).split() if not word.isdigit()]))\ntest_df['review_text'] = test_df['review_text'].apply(remove_stopword)\ntest_df['review_text'] = test_df['review_text'].apply(remove_punc)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"two_way_stemmer = TwoWayStemmer()\n\n# Assuming 'train_df' is your training dataframe with 'review_text' column\ntest_df['review_text'] = test_df['review_text'].apply(lambda x: two_way_stemmer.stem_text(x))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# TF-IDF transformation on test data\ntest_tfidf = vectorizer.transform(test_df['review_text'])  # Assuming 'review_text' is the column name\n\n# Convert TF-IDF transformed test data to SparseTensor\ntest_sparse = convert_to_sparse_tensor(test_tfidf)\n\n# Reorder the SparseTensor\ntest_reordered = tf.sparse.reorder(test_sparse)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Make predictions on the test data\npredictions = loaded_model.predict(test_reordered)\n\n# If you want the predicted classes:\npredicted_classes = np.argmax(predictions, axis=1)\n\n# If you want the predicted probabilities for each class:\npredicted_probabilities = predictions","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Assuming test_df['review_id'] and predictions are two-dimensional arrays of shape (270000, 1)\npredictions_df = pd.DataFrame({'review_id': test_df['review_id'], 'rating': predicted_classes})\n\n# Save the DataFrame to a CSV file\npredictions_df.to_csv('predictions3.csv', index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predictions_df['rating'].value_counts()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Predict on the test set\npredictions = model.predict(X_test_tfidf)\n\n# Get the predicted classes\npredicted_classes = predictions.argmax(axis=1)\n\n# Evaluate the model\naccuracy = accuracy_score(y_test, predicted_classes)\nprint(f\"Accuracy: {accuracy:.2f}\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predictions_df = pd.DataFrame({'review_id': test_df['review_id'], 'rating': predictions})\n\n# Save the DataFrame to a CSV file\npredictions_df.to_csv('predictions4.csv', index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom scipy.stats import uniform\n\n# Assuming X_train and y_train are your training data\n\n# TF-IDF vectorization for text data\nvectorizer = TfidfVectorizer()\nX_train_tfidf = vectorizer.fit_transform(X_train)\nX_test_tfidf = vectorizer.transform(X_test)\n\n# Define the parameters you want to tune\nparam_dist = {\n    'C': uniform(0.1, 10.0),  # Example range for regularization parameter C\n    'solver': ['liblinear', 'lbfgs'],\n}\n\n# Create the Logistic Regression model\nlogistic = LogisticRegression()\n\n# Perform randomized search with parallel processing\nrandom_search = RandomizedSearchCV(logistic, param_dist, cv=5, scoring='accuracy', n_iter=10, n_jobs=4)\nrandom_search.fit(X_train_tfidf, y_train)\n\n# Get the best parameters and the best model\nbest_params = random_search.best_params_\nbest_model = random_search.best_estimator_\n\n# Predict on the test set\npredictions = best_model.predict(X_test_tfidf)\n\n# Evaluate the model\naccuracy = accuracy_score(y_test, predictions)\nreport = classification_report(y_test, predictions)\n\nprint(f\"Best parameters: {best_params}\")\nprint(f\"Accuracy: {accuracy:.2f}\")\nprint(\"Classification Report:\")\nprint(report)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# After running RandomizedSearchCV\n# Access the best parameters and best model using the correct attributes\nbest_params = random_search.best_params_\nbest_model = random_search.best_estimator_\n\n# Predict on the test set using the best model\npredictions = best_model.predict(X_test_tfidf)\n\n# Evaluate the model\naccuracy = accuracy_score(y_test, predictions)\nreport = classification_report(y_test, predictions)\n\nprint(f\"Best parameters: {best_params}\")\nprint(f\"Accuracy: {accuracy:.2f}\")\nprint(\"Classification Report:\")\nprint(report)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom sklearn.model_selection import train_test_split\n\n# Assuming X_train and y_train are your training data\n\n# TF-IDF vectorization for text data\nvectorizer = TfidfVectorizer()\nX_train_tfidf = vectorizer.fit_transform(X_train)\nX_test_tfidf = vectorizer.transform(X_test)\n\n# Split the data into training and testing sets\nX_train_split, X_val, y_train_split, y_val = train_test_split(X_train_tfidf, y_train, test_size=0.2, random_state=42)\n\n# Create a Logistic Regression model\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"logistic = LogisticRegression(max_iter=10000, class_weight='balanced')\n\n# Fit the model\nlogistic.fit(X_train_split, y_train_split)\n\n# Predict on the test set\npredictions = logistic.predict(X_test_tfidf)\n\n# Evaluate the model\naccuracy = accuracy_score(y_test, predictions)\nreport = classification_report(y_test, predictions)\n\nprint(f\"Accuracy: {accuracy:.2f}\")\nprint(\"Classification Report:\")\nprint(report)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predictions = logistic.predict(test_tfidf)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Assuming test_df['review_id'] and predictions are two-dimensional arrays of shape (270000, 1)\npredictions_df = pd.DataFrame({'review_id': test_df['review_id'], 'rating': predictions})\n\n# Save the DataFrame to a CSV file\npredictions_df.to_csv('predictions3.csv', index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\n# Assuming 'data' is your DataFrame\npredictions_df.to_csv('predictions3.csv', index=False)\n\n# Then generate a link to download the file\nfrom IPython.display import FileLink\nFileLink('predictions3.csv')\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def check_input_characters(input_str):\n    for char in input_str:\n        if not char.isalnum() and not char.isspace() and char != '\\t':\n            print(f\"Invalid character: {char}\")\n            return char\n    return \" \"\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"demo = new_df['review_text'].apply(check_input_characters)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"demo.value_counts()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null}]}