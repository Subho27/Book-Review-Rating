{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":63741,"databundleVersionId":6966274,"sourceType":"competition"}],"dockerImageVersionId":30587,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-23T10:04:07.146287Z","iopub.execute_input":"2023-11-23T10:04:07.147006Z","iopub.status.idle":"2023-11-23T10:04:07.530426Z","shell.execute_reply.started":"2023-11-23T10:04:07.146967Z","shell.execute_reply":"2023-11-23T10:04:07.527890Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset = pd.read_csv(\"/kaggle/input/book-rating-prediction01/Train.csv\",encoding=\"latin\")\ndf = pd.DataFrame(dataset)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-23T10:04:07.531930Z","iopub.execute_input":"2023-11-23T10:04:07.532447Z","iopub.status.idle":"2023-11-23T10:04:24.385423Z","shell.execute_reply.started":"2023-11-23T10:04:07.532421Z","shell.execute_reply":"2023-11-23T10:04:24.383979Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"result = df.dtypes\nfor i in range(0, len(result)):\n  print(df.columns[i], result[i])","metadata":{"execution":{"iopub.status.busy":"2023-11-23T10:04:24.386898Z","iopub.execute_input":"2023-11-23T10:04:24.387261Z","iopub.status.idle":"2023-11-23T10:04:24.394975Z","shell.execute_reply.started":"2023-11-23T10:04:24.387227Z","shell.execute_reply":"2023-11-23T10:04:24.393492Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for i in df.columns:\n    print(i,df[i].count())","metadata":{"execution":{"iopub.status.busy":"2023-11-23T10:04:24.396253Z","iopub.execute_input":"2023-11-23T10:04:24.396980Z","iopub.status.idle":"2023-11-23T10:04:24.626220Z","shell.execute_reply.started":"2023-11-23T10:04:24.396948Z","shell.execute_reply":"2023-11-23T10:04:24.624700Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"new_df = df\nnew_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-23T10:04:24.628169Z","iopub.execute_input":"2023-11-23T10:04:24.628569Z","iopub.status.idle":"2023-11-23T10:04:24.643869Z","shell.execute_reply.started":"2023-11-23T10:04:24.628535Z","shell.execute_reply":"2023-11-23T10:04:24.642546Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"new_df['year'] = new_df['date_added'].apply(lambda x: x[-4:] if isinstance(x, str) else None)","metadata":{"execution":{"iopub.status.busy":"2023-11-23T10:04:24.648016Z","iopub.execute_input":"2023-11-23T10:04:24.648507Z","iopub.status.idle":"2023-11-23T10:04:24.845389Z","shell.execute_reply.started":"2023-11-23T10:04:24.648473Z","shell.execute_reply":"2023-11-23T10:04:24.844249Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"new_df['review_text'] = new_df['review_text'].str.lower()","metadata":{"execution":{"iopub.status.busy":"2023-11-23T10:04:24.846771Z","iopub.execute_input":"2023-11-23T10:04:24.847281Z","iopub.status.idle":"2023-11-23T10:04:25.610723Z","shell.execute_reply.started":"2023-11-23T10:04:24.847250Z","shell.execute_reply":"2023-11-23T10:04:25.609426Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"new_df['review_text']","metadata":{"execution":{"iopub.status.busy":"2023-11-23T10:04:25.612541Z","iopub.execute_input":"2023-11-23T10:04:25.613024Z","iopub.status.idle":"2023-11-23T10:04:25.621411Z","shell.execute_reply.started":"2023-11-23T10:04:25.612980Z","shell.execute_reply":"2023-11-23T10:04:25.620136Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### HTML Tag and urls removal","metadata":{}},{"cell_type":"code","source":"import re\n\ndef remove_html_tags_and_urls(text):\n    clean = re.sub(r'[\\t\\n]', '', text)\n    clean = re.sub(r'<.*?>', '', clean)\n    clean = re.sub(r'https?://\\S+|www\\.\\S+', '', clean)\n    clean = re.sub(r'\\d+', '', clean)\n    return clean","metadata":{"execution":{"iopub.status.busy":"2023-11-23T10:04:25.622805Z","iopub.execute_input":"2023-11-23T10:04:25.624133Z","iopub.status.idle":"2023-11-23T10:04:25.633407Z","shell.execute_reply.started":"2023-11-23T10:04:25.624071Z","shell.execute_reply":"2023-11-23T10:04:25.631966Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"new_df['review_text'] = new_df['review_text'].apply(remove_html_tags_and_urls)","metadata":{"execution":{"iopub.status.busy":"2023-11-23T10:04:25.635258Z","iopub.execute_input":"2023-11-23T10:04:25.635665Z","iopub.status.idle":"2023-11-23T10:04:50.678058Z","shell.execute_reply.started":"2023-11-23T10:04:25.635640Z","shell.execute_reply":"2023-11-23T10:04:50.676425Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"new_df['review_text']","metadata":{"execution":{"iopub.status.busy":"2023-11-23T10:04:50.679560Z","iopub.execute_input":"2023-11-23T10:04:50.680045Z","iopub.status.idle":"2023-11-23T10:04:50.689322Z","shell.execute_reply.started":"2023-11-23T10:04:50.680015Z","shell.execute_reply":"2023-11-23T10:04:50.688156Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Remove Punctuation","metadata":{}},{"cell_type":"code","source":"import string\nstring.punctuation","metadata":{"execution":{"iopub.status.busy":"2023-11-23T10:04:50.690636Z","iopub.execute_input":"2023-11-23T10:04:50.690954Z","iopub.status.idle":"2023-11-23T10:04:50.701655Z","shell.execute_reply.started":"2023-11-23T10:04:50.690929Z","shell.execute_reply":"2023-11-23T10:04:50.700785Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"punc = '''!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'''","metadata":{"execution":{"iopub.status.busy":"2023-11-23T10:04:50.702552Z","iopub.execute_input":"2023-11-23T10:04:50.702903Z","iopub.status.idle":"2023-11-23T10:04:50.714204Z","shell.execute_reply.started":"2023-11-23T10:04:50.702875Z","shell.execute_reply":"2023-11-23T10:04:50.713137Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def remove_punc(text):\n    return text.translate(str.maketrans('','', punc))","metadata":{"execution":{"iopub.status.busy":"2023-11-23T10:04:50.715056Z","iopub.execute_input":"2023-11-23T10:04:50.715335Z","iopub.status.idle":"2023-11-23T10:04:50.725923Z","shell.execute_reply.started":"2023-11-23T10:04:50.715309Z","shell.execute_reply":"2023-11-23T10:04:50.723861Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"new_df['review_text'] = new_df['review_text'].apply(remove_punc)","metadata":{"execution":{"iopub.status.busy":"2023-11-23T10:04:50.727320Z","iopub.execute_input":"2023-11-23T10:04:50.727783Z","iopub.status.idle":"2023-11-23T10:04:54.580293Z","shell.execute_reply.started":"2023-11-23T10:04:50.727751Z","shell.execute_reply":"2023-11-23T10:04:54.578890Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"new_df['review_text']","metadata":{"execution":{"iopub.status.busy":"2023-11-23T10:04:54.581359Z","iopub.execute_input":"2023-11-23T10:04:54.581659Z","iopub.status.idle":"2023-11-23T10:04:54.593158Z","shell.execute_reply.started":"2023-11-23T10:04:54.581631Z","shell.execute_reply":"2023-11-23T10:04:54.591602Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Stopwords Removal","metadata":{}},{"cell_type":"code","source":"from nltk.corpus import stopwords","metadata":{"execution":{"iopub.status.busy":"2023-11-23T10:04:54.594966Z","iopub.execute_input":"2023-11-23T10:04:54.595322Z","iopub.status.idle":"2023-11-23T10:04:54.601842Z","shell.execute_reply.started":"2023-11-23T10:04:54.595292Z","shell.execute_reply":"2023-11-23T10:04:54.600240Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"stopwords.words('english')","metadata":{"execution":{"iopub.status.busy":"2023-11-23T10:04:54.603804Z","iopub.execute_input":"2023-11-23T10:04:54.605044Z","iopub.status.idle":"2023-11-23T10:04:54.624429Z","shell.execute_reply.started":"2023-11-23T10:04:54.605007Z","shell.execute_reply":"2023-11-23T10:04:54.622705Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# def remove_stopwords(text):\n#     new_text = []\n#     for word in text.split():\n#         if word in stopwords.words('english'):\n#             new_text.append('')\n#         else:\n#             new_text.append(word)\n#     x = new_text[:]\n#     new_text.clear()\n#     return \" \".join(x)","metadata":{"execution":{"iopub.status.busy":"2023-11-23T10:04:54.626178Z","iopub.execute_input":"2023-11-23T10:04:54.626528Z","iopub.status.idle":"2023-11-23T10:04:54.631380Z","shell.execute_reply.started":"2023-11-23T10:04:54.626499Z","shell.execute_reply":"2023-11-23T10:04:54.629782Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from nltk.corpus import stopwords\n\nstop_words = set(stopwords.words('english'))\n\ndef remove_stopword(text):\n    words = text.split()\n    filtered_words = [word for word in words if word not in stop_words]\n    return ' '.join(filtered_words)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-23T10:04:54.633583Z","iopub.execute_input":"2023-11-23T10:04:54.634029Z","iopub.status.idle":"2023-11-23T10:04:54.642248Z","shell.execute_reply.started":"2023-11-23T10:04:54.633992Z","shell.execute_reply":"2023-11-23T10:04:54.640729Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"new_df['review_text'] = new_df['review_text'].apply(remove_stopword)","metadata":{"execution":{"iopub.status.busy":"2023-11-23T10:04:54.647798Z","iopub.execute_input":"2023-11-23T10:04:54.648179Z","iopub.status.idle":"2023-11-23T10:05:11.951212Z","shell.execute_reply.started":"2023-11-23T10:04:54.648154Z","shell.execute_reply":"2023-11-23T10:05:11.949796Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"new_df['review_text']","metadata":{"execution":{"iopub.status.busy":"2023-11-23T10:05:11.952841Z","iopub.execute_input":"2023-11-23T10:05:11.953217Z","iopub.status.idle":"2023-11-23T10:05:11.962732Z","shell.execute_reply.started":"2023-11-23T10:05:11.953185Z","shell.execute_reply":"2023-11-23T10:05:11.961743Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Tokenization and Stemming","metadata":{}},{"cell_type":"code","source":"import nltk\nfrom nltk.stem.porter import PorterStemmer\nfrom nltk.tokenize import word_tokenize, sent_tokenize","metadata":{"execution":{"iopub.status.busy":"2023-11-23T10:05:11.964002Z","iopub.execute_input":"2023-11-23T10:05:11.964982Z","iopub.status.idle":"2023-11-23T10:05:11.972882Z","shell.execute_reply.started":"2023-11-23T10:05:11.964932Z","shell.execute_reply":"2023-11-23T10:05:11.971971Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ps = PorterStemmer()\ndef stemng(text):\n    token = word_tokenize(text)\n    return \" \".join(ps.stem(word) for word in token)","metadata":{"execution":{"iopub.status.busy":"2023-11-23T10:05:11.974065Z","iopub.execute_input":"2023-11-23T10:05:11.975280Z","iopub.status.idle":"2023-11-23T10:05:11.984465Z","shell.execute_reply.started":"2023-11-23T10:05:11.975243Z","shell.execute_reply":"2023-11-23T10:05:11.982716Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"new_df['review_text'] = new_df['review_text'].apply(stemng)","metadata":{"execution":{"iopub.status.busy":"2023-11-23T10:05:11.986585Z","iopub.execute_input":"2023-11-23T10:05:11.987000Z","iopub.status.idle":"2023-11-23T10:35:39.869382Z","shell.execute_reply.started":"2023-11-23T10:05:11.986965Z","shell.execute_reply":"2023-11-23T10:35:39.867863Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"new_df['review_text']","metadata":{"execution":{"iopub.status.busy":"2023-11-23T10:35:39.871053Z","iopub.execute_input":"2023-11-23T10:35:39.871424Z","iopub.status.idle":"2023-11-23T10:35:39.880040Z","shell.execute_reply.started":"2023-11-23T10:35:39.871395Z","shell.execute_reply":"2023-11-23T10:35:39.879115Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Model","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\nimport scipy.sparse as sp\n\n# Split the data into features and target\nX = new_df[['review_text', 'n_votes', 'n_comments']]\ny = new_df['rating']\n\n# Split the data into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n\n# TF-IDF vectorization for text data\nvectorizer = TfidfVectorizer()\nX_train_tfidf = vectorizer.fit_transform(X_train['review_text'])\nX_test_tfidf = vectorizer.transform(X_test['review_text'])\n\n# Combine TF-IDF vectors with numerical columns\nX_train_combined = sp.hstack((X_train_tfidf, X_train[['n_votes', 'n_comments']].values))\nX_test_combined = sp.hstack((X_test_tfidf, X_test[['n_votes', 'n_comments']].values))","metadata":{"execution":{"iopub.status.busy":"2023-11-23T10:35:39.881304Z","iopub.execute_input":"2023-11-23T10:35:39.881639Z","iopub.status.idle":"2023-11-23T10:36:30.832645Z","shell.execute_reply.started":"2023-11-23T10:35:39.881606Z","shell.execute_reply":"2023-11-23T10:36:30.831080Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Fit logistic regression model (multinomial)\nlogistic_model = LogisticRegression(multi_class='multinomial', solver='lbfgs')\nlogistic_model.fit(X_train_tfidf, y_train)\n\n# Predict on the test set\npredictions = logistic_model.predict(X_test_tfidf)\n\n# Evaluate the model\naccuracy = accuracy_score(y_test, predictions)\nreport = classification_report(y_test, predictions)\n\nprint(f\"Accuracy: {accuracy:.2f}\")\nprint(\"Classification Report:\")\nprint(report)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-23T10:36:30.834840Z","iopub.execute_input":"2023-11-23T10:36:30.835265Z","iopub.status.idle":"2023-11-23T10:38:26.185378Z","shell.execute_reply.started":"2023-11-23T10:36:30.835233Z","shell.execute_reply":"2023-11-23T10:38:26.183629Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report\n\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n\n# TF-IDF vectorization for text data\nvectorizer = TfidfVectorizer()\nX_train_tfidf = vectorizer.fit_transform(X_train['review_text'])\nX_test_tfidf = vectorizer.transform(X_test['review_text'])\n\n\n# Fit Naive Bayes (Multinomial) model\nnb_model = MultinomialNB()\nnb_model.fit(X_train_tfidf, y_train)\n\n# Predict on the test set\npredictions = nb_model.predict(X_test_tfidf)\n\n# Evaluate the model\naccuracy = accuracy_score(y_test, predictions)\nreport = classification_report(y_test, predictions)\n\nprint(f\"Accuracy: {accuracy:.2f}\")\nprint(\"Classification Report:\")\nprint(report)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-11-23T09:56:55.639708Z","iopub.execute_input":"2023-11-23T09:56:55.640353Z","iopub.status.idle":"2023-11-23T09:57:23.162053Z","shell.execute_reply.started":"2023-11-23T09:56:55.640136Z","shell.execute_reply":"2023-11-23T09:57:23.160870Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report\nimport pandas as pd\nimport scipy.sparse as sp\n\n\n# Split the data into features and target\nX = new_df[['review_text', 'n_votes', 'n_comments']]\ny = new_df['rating']\n\n# Split the data into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n\n# TF-IDF vectorization for text data\nvectorizer = TfidfVectorizer()\nX_train_tfidf = vectorizer.fit_transform(X_train['review_text'])\nX_test_tfidf = vectorizer.transform(X_test['review_text'])\n\n# Combine TF-IDF vectors with numerical columns\nX_train_combined = sp.hstack((X_train_tfidf, X_train[['n_votes', 'n_comments']].values))\nX_test_combined = sp.hstack((X_test_tfidf, X_test[['n_votes', 'n_comments']].values))\n\n# Fit SVM model\nsvm_model = SVC(kernel='linear')  # You can choose different kernels like 'rbf', 'poly', etc.\nsvm_model.fit(X_train_combined, y_train)\n\n# Predict on the test set\npredictions = svm_model.predict(X_test_combined)\n\n# Evaluate the model\naccuracy = accuracy_score(y_test, predictions)\nreport = classification_report(y_test, predictions)\n\nprint(f\"Accuracy: {accuracy:.2f}\")\nprint(\"Classification Report:\")\nprint(report)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-22T20:02:35.452396Z","iopub.execute_input":"2023-11-22T20:02:35.452692Z","iopub.status.idle":"2023-11-22T20:03:10.945226Z","shell.execute_reply.started":"2023-11-22T20:02:35.452671Z","shell.execute_reply":"2023-11-22T20:03:10.944295Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report\nimport pandas as pd\nimport scipy.sparse as sp\n\n\n\n# Split the data into features and target\nX = new_df[['review_text', 'n_votes', 'n_comments']]\ny = new_df['rating']\n\n# Split the data into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n\n# TF-IDF vectorization for text data\nvectorizer = TfidfVectorizer()\nX_train_tfidf = vectorizer.fit_transform(X_train['review_text'])\nX_test_tfidf = vectorizer.transform(X_test['review_text'])\n\n# Combine TF-IDF vectors with numerical columns\nX_train_combined = sp.hstack((X_train_tfidf, X_train[['n_votes', 'n_comments']].values))\nX_test_combined = sp.hstack((X_test_tfidf, X_test[['n_votes', 'n_comments']].values))\n\n# Fit Random Forest model\nrf_model = RandomForestClassifier(n_estimators=100, random_state=42)\nrf_model.fit(X_train_combined, y_train)\n\n# Predict on the test set\npredictions = rf_model.predict(X_test_combined)\n\n# Evaluate the model\naccuracy = accuracy_score(y_test, predictions)\nreport = classification_report(y_test, predictions)\n\nprint(f\"Accuracy: {accuracy:.2f}\")\nprint(\"Classification Report:\")\nprint(report)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-22T19:59:50.081771Z","iopub.execute_input":"2023-11-22T19:59:50.082103Z","iopub.status.idle":"2023-11-22T19:59:58.762068Z","shell.execute_reply.started":"2023-11-22T19:59:50.082078Z","shell.execute_reply":"2023-11-22T19:59:58.761494Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report\nimport pandas as pd\nimport scipy.sparse as sp\n\n\n# Split the data into features and target\nX = new_df[['review_text', 'n_votes', 'n_comments']]\ny = new_df['rating']\n\n# Split the data into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n\n# TF-IDF vectorization for text data\nvectorizer = TfidfVectorizer()\nX_train_tfidf = vectorizer.fit_transform(X_train['review_text'])\nX_test_tfidf = vectorizer.transform(X_test['review_text'])\n\n# Combine TF-IDF vectors with numerical columns\nX_train_combined = sp.hstack((X_train_tfidf, X_train[['n_votes', 'n_comments']].values))\nX_test_combined = sp.hstack((X_test_tfidf, X_test[['n_votes', 'n_comments']].values))\n\n# Fit KNN model\nknn_model = KNeighborsClassifier(n_neighbors=750)  # Adjust the number of neighbors as needed\nknn_model.fit(X_train_combined, y_train)\n\n# Predict on the test set\npredictions = knn_model.predict(X_test_combined)\n\n# Evaluate the model\naccuracy = accuracy_score(y_test, predictions)\nreport = classification_report(y_test, predictions)\n\nprint(f\"Accuracy: {accuracy:.2f}\")\nprint(\"Classification Report:\")\nprint(report)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-22T20:05:26.059962Z","iopub.execute_input":"2023-11-22T20:05:26.060472Z","iopub.status.idle":"2023-11-22T20:05:30.529934Z","shell.execute_reply.started":"2023-11-22T20:05:26.060448Z","shell.execute_reply":"2023-11-22T20:05:30.527890Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report\nimport pandas as pd\nimport scipy.sparse as sp\n\n\n# Split the data into features and target\nX = new_df[['review_text', 'n_votes', 'n_comments']]\ny = new_df['rating']\n\n# Split the data into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n\n# TF-IDF vectorization for text data\nvectorizer = TfidfVectorizer()\nX_train_tfidf = vectorizer.fit_transform(X_train['review_text'])\nX_test_tfidf = vectorizer.transform(X_test['review_text'])\n\n# Combine TF-IDF vectors with numerical columns\nX_train_combined = sp.hstack((X_train_tfidf, X_train[['n_votes', 'n_comments']].values))\nX_test_combined = sp.hstack((X_test_tfidf, X_test[['n_votes', 'n_comments']].values))\n\n# Fit MLPClassifier (Neural Network)\nmlp_model = MLPClassifier(hidden_layer_sizes=(100, ), max_iter=1000, random_state=42)\nmlp_model.fit(X_train_combined, y_train)\n\n# Predict on the test set\npredictions = mlp_model.predict(X_test_combined)\n\n# Evaluate the model\naccuracy = accuracy_score(y_test, predictions)\nreport = classification_report(y_test, predictions)\n\nprint(f\"Accuracy: {accuracy:.2f}\")\nprint(\"Classification Report:\")\nprint(report)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-22T20:06:41.086576Z","iopub.execute_input":"2023-11-22T20:06:41.087151Z","iopub.status.idle":"2023-11-22T20:08:05.759991Z","shell.execute_reply.started":"2023-11-22T20:06:41.087129Z","shell.execute_reply":"2023-11-22T20:08:05.759209Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### BERT","metadata":{}},{"cell_type":"code","source":"from bert import tokenization\nimport tensorflow as tf\nimport tensorflow_hub as hub\nfrom keras.utils import to_categorical\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2023-11-23T06:54:09.869323Z","iopub.execute_input":"2023-11-23T06:54:09.869820Z","iopub.status.idle":"2023-11-23T06:54:09.881426Z","shell.execute_reply.started":"2023-11-23T06:54:09.869779Z","shell.execute_reply":"2023-11-23T06:54:09.880238Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"m_url = 'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2'\nbert_layer = hub.KerasLayer(m_url, trainable=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-23T06:54:32.265169Z","iopub.execute_input":"2023-11-23T06:54:32.265603Z","iopub.status.idle":"2023-11-23T06:54:39.194248Z","shell.execute_reply.started":"2023-11-23T06:54:32.265568Z","shell.execute_reply":"2023-11-23T06:54:39.193009Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\ndo_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\ntokenizer = tokenization.FullTokenizer(vocab_file, do_lower_case)\n\ndef bert_encode(texts, tokenizer, max_len=512):\n    all_tokens = []\n    all_masks = []\n    all_segments = []\n    \n    for text in texts:\n        text = tokenizer.tokenize(text)\n        \n        text = text[:max_len-2]\n        input_sequence = text \n\n        \n        tokens = tokenizer.convert_tokens_to_ids(input_sequence)\n        \n        \n        all_tokens.append(tokens)\n        \n    return np.array(all_tokens)","metadata":{"execution":{"iopub.status.busy":"2023-11-23T07:12:36.644584Z","iopub.execute_input":"2023-11-23T07:12:36.645027Z","iopub.status.idle":"2023-11-23T07:12:36.763862Z","shell.execute_reply.started":"2023-11-23T07:12:36.644994Z","shell.execute_reply":"2023-11-23T07:12:36.762419Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def build_model(bert_layer, max_len=512):\n    input_word_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n    input_mask = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\n    segment_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"segment_ids\")\n    \n    pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n    \n    clf_output = sequence_output[:, 0, :]\n    \n    lay = tf.keras.layers.Dense(64, activation='relu')(clf_output)\n    lay = tf.keras.layers.Dropout(0.2)(lay)\n    lay = tf.keras.layers.Dense(32, activation='relu')(lay)\n    lay = tf.keras.layers.Dropout(0.2)(lay)\n    out = tf.keras.layers.Dense(5, activation='softmax')(lay)\n    \n    model = tf.keras.models.Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=out)\n    model.compile(tf.keras.optimizers.Adam(lr=2e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2023-11-23T07:12:37.478772Z","iopub.execute_input":"2023-11-23T07:12:37.479203Z","iopub.status.idle":"2023-11-23T07:12:37.488999Z","shell.execute_reply.started":"2023-11-23T07:12:37.479171Z","shell.execute_reply":"2023-11-23T07:12:37.488025Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import absl.flags as flags\n\n# Reset or clear FLAGS before using the tokenizer\nflags.FLAGS = flags.FlagValues()\n","metadata":{"execution":{"iopub.status.busy":"2023-11-23T07:11:49.466792Z","iopub.execute_input":"2023-11-23T07:11:49.467238Z","iopub.status.idle":"2023-11-23T07:11:49.473742Z","shell.execute_reply.started":"2023-11-23T07:11:49.467203Z","shell.execute_reply":"2023-11-23T07:11:49.472435Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"max_len = 250\ntrain_input = bert_encode(new_df['review_text'].tolist(), tokenizer, max_len=max_len)\n\ntrain_labels = new_df['rating']","metadata":{"execution":{"iopub.status.busy":"2023-11-23T07:12:39.533419Z","iopub.execute_input":"2023-11-23T07:12:39.534699Z","iopub.status.idle":"2023-11-23T07:12:39.690543Z","shell.execute_reply.started":"2023-11-23T07:12:39.534641Z","shell.execute_reply":"2023-11-23T07:12:39.688924Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = build_model(bert_layer, max_len=max_len)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-11-23T07:02:36.032881Z","iopub.execute_input":"2023-11-23T07:02:36.033332Z","iopub.status.idle":"2023-11-23T07:02:36.289691Z","shell.execute_reply.started":"2023-11-23T07:02:36.033297Z","shell.execute_reply":"2023-11-23T07:02:36.288566Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_input = new_df['review_text']\ntrain_labels = new_df['rating']","metadata":{"execution":{"iopub.status.busy":"2023-11-23T07:02:48.457033Z","iopub.execute_input":"2023-11-23T07:02:48.457495Z","iopub.status.idle":"2023-11-23T07:02:48.467245Z","shell.execute_reply.started":"2023-11-23T07:02:48.457444Z","shell.execute_reply":"2023-11-23T07:02:48.465865Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"checkpoint = tf.keras.callbacks.ModelCheckpoint('model.h5', monitor='val_accuracy', save_best_only=True, verbose=1)\nearlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=5, verbose=1)\n\ntrain_sh = model.fit(\n    train_input, train_labels,\n    validation_split=0.2,\n    epochs=3,\n    callbacks=[checkpoint, earlystopping],\n    batch_size=32,\n    verbose=1\n)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-23T07:03:28.527314Z","iopub.execute_input":"2023-11-23T07:03:28.528591Z","iopub.status.idle":"2023-11-23T07:03:28.732400Z","shell.execute_reply.started":"2023-11-23T07:03:28.528544Z","shell.execute_reply":"2023-11-23T07:03:28.730584Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def bert_encode_single_input(texts, tokenizer, max_len=512):\n    all_tokens = []\n    \n    for text in texts:\n        text = tokenizer.tokenize(text)\n        text = text[:max_len - 2]\n        input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\n        pad_len = max_len - len(input_sequence)\n        \n        tokens = tokenizer.convert_tokens_to_ids(input_sequence) + [0] * pad_len\n        all_tokens.append(tokens)\n        \n    return np.array(all_tokens)\n\n# Encode using the modified function\nmax_len = 250\ntrain_input = bert_encode_single_input(new_df['review_text'], tokenizer, max_len=max_len)\ntrain_labels = new_df['rating']","metadata":{"execution":{"iopub.status.busy":"2023-11-23T07:01:06.373886Z","iopub.execute_input":"2023-11-23T07:01:06.374607Z","iopub.status.idle":"2023-11-23T07:01:06.615751Z","shell.execute_reply.started":"2023-11-23T07:01:06.374564Z","shell.execute_reply":"2023-11-23T07:01:06.614077Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Prediction","metadata":{}},{"cell_type":"code","source":"test_df = pd.read_csv('/kaggle/input/book-rating-prediction01/Test.csv')","metadata":{"execution":{"iopub.status.busy":"2023-11-23T10:38:26.187432Z","iopub.execute_input":"2023-11-23T10:38:26.187921Z","iopub.status.idle":"2023-11-23T10:38:33.507440Z","shell.execute_reply.started":"2023-11-23T10:38:26.187882Z","shell.execute_reply":"2023-11-23T10:38:33.506181Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Preprocessing Testing Data","metadata":{}},{"cell_type":"code","source":"test_df['review_text'] = test_df['review_text'].str.lower()","metadata":{"execution":{"iopub.status.busy":"2023-11-23T10:38:33.509106Z","iopub.execute_input":"2023-11-23T10:38:33.509497Z","iopub.status.idle":"2023-11-23T10:38:33.795492Z","shell.execute_reply.started":"2023-11-23T10:38:33.509466Z","shell.execute_reply":"2023-11-23T10:38:33.794483Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_df['review_text'] = test_df['review_text'].apply(remove_html_tags_and_urls)","metadata":{"execution":{"iopub.status.busy":"2023-11-23T10:38:33.796672Z","iopub.execute_input":"2023-11-23T10:38:33.797041Z","iopub.status.idle":"2023-11-23T10:38:44.658597Z","shell.execute_reply.started":"2023-11-23T10:38:33.797011Z","shell.execute_reply":"2023-11-23T10:38:44.657493Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_df['review_text'] = test_df['review_text'].apply(remove_punc)","metadata":{"execution":{"iopub.status.busy":"2023-11-23T10:38:44.670782Z","iopub.execute_input":"2023-11-23T10:38:44.671276Z","iopub.status.idle":"2023-11-23T10:38:46.286518Z","shell.execute_reply.started":"2023-11-23T10:38:44.671240Z","shell.execute_reply":"2023-11-23T10:38:46.285084Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_df['review_text'] = test_df['review_text'].apply(remove_stopword)","metadata":{"execution":{"iopub.status.busy":"2023-11-23T10:38:46.289641Z","iopub.execute_input":"2023-11-23T10:38:46.290016Z","iopub.status.idle":"2023-11-23T10:38:53.824778Z","shell.execute_reply.started":"2023-11-23T10:38:46.289987Z","shell.execute_reply":"2023-11-23T10:38:53.823551Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_df['review_text'] = test_df['review_text'].apply(stemng)","metadata":{"execution":{"iopub.status.busy":"2023-11-23T10:38:53.833292Z","iopub.execute_input":"2023-11-23T10:38:53.833703Z","iopub.status.idle":"2023-11-23T10:51:54.704950Z","shell.execute_reply.started":"2023-11-23T10:38:53.833654Z","shell.execute_reply":"2023-11-23T10:51:54.703285Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Y_test = vectorizer.transform(test_df['review_text'])","metadata":{"execution":{"iopub.status.busy":"2023-11-23T10:51:54.706583Z","iopub.execute_input":"2023-11-23T10:51:54.706919Z","iopub.status.idle":"2023-11-23T10:52:14.591337Z","shell.execute_reply.started":"2023-11-23T10:51:54.706894Z","shell.execute_reply":"2023-11-23T10:52:14.590320Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predictions = logistic_model.predict(Y_test)","metadata":{"execution":{"iopub.status.busy":"2023-11-23T10:52:14.592603Z","iopub.execute_input":"2023-11-23T10:52:14.593266Z","iopub.status.idle":"2023-11-23T10:52:14.776398Z","shell.execute_reply.started":"2023-11-23T10:52:14.593231Z","shell.execute_reply":"2023-11-23T10:52:14.775441Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predictions_df = pd.DataFrame({'review_id': test_df['review_id'], 'rating': predictions})\npredictions_df.to_csv('predictions.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-11-23T10:52:14.778286Z","iopub.execute_input":"2023-11-23T10:52:14.778681Z","iopub.status.idle":"2023-11-23T10:52:15.129655Z","shell.execute_reply.started":"2023-11-23T10:52:14.778648Z","shell.execute_reply":"2023-11-23T10:52:15.128175Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_df['review_text']","metadata":{"execution":{"iopub.status.busy":"2023-11-23T09:27:05.562358Z","iopub.execute_input":"2023-11-23T09:27:05.562771Z","iopub.status.idle":"2023-11-23T09:27:05.571714Z","shell.execute_reply.started":"2023-11-23T09:27:05.562741Z","shell.execute_reply":"2023-11-23T09:27:05.570532Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null}]}